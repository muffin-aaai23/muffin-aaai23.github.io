<!DOCTYPE html>
<html lang="en">
<head>
<title>Multimodal AI for Financial Forecasting Workshop</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>
<body id="top">
<div class="wrapper row1">
  <header id="header" class="hoc clear">
    <!-- ################################################################################################ -->
    <div id="logo" class="fl_left">
      <h1><a href="index.html">Muffin@AAAI 2023</a></h1>
    </div>
    <nav id="mainav" class="fl_right">
      <ul class="clear">
        <li><a href="index.html">Home</a></li>
        <li><a href="schedule.html">Schedule</a></li>
        <li><a href="talks.html">Invited Talks</a></li>
        <li><a href="tutorial.html">Invited Tutorials</a></li>
        <li class="active"><a href="cfp.html">CFP</a></li>
        <li><a href="shared_task.html">Shared Tasks</a></li>
        <li><a href="index.html#important-date">Important Dates</a></li>
        <li><a href="index.html#organizer">Organizers</a></li>
      </ul>
    </nav>
    <!-- ################################################################################################ -->
  </header>
</div>
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<div class="wrapper bgded overlay" style="background-image:url('images/demo/backgrounds/muffin.jpeg');">
  <div id="pageintro" class="hoc clear">
    <!-- ################################################################################################ -->
      <h3 class="heading">The AAAI-2023 Workshop on <br>Multimodal AI for Financial Forecasting</h3>
      <h4>Feb 14, 2023: 8:30 AM-12:30 PM</h4>
      <h4>Location: Washington DC, USA</h4>
    <!-- ################################################################################################ -->
  </div>
</div>
<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Introduction</h6>
        <p>
          Financial forecasting is an essential task that helps investors make sound investment decisions and wealth creation. With increasing public interest in trading stocks, cryptocurrencies, bonds, commodities, currencies, crypto coins and non-fungible tokens (NFTs), there have been several attempts to utilize unstructured data for financial forecasting. Unparalleled advances in multimodal deep learning have made it possible to utilize multimedia such as textual reports, news articles, streaming video content, audio conference calls, user social media posts, customer web searches, etc for identifying profit creation opportunities in the market. E.g., how can we leverage new and better information to predict movements in stocks and cryptocurrencies well before others? However, there are several hurdles towards realizing this goal - (1) large volumes of chaotic data, (2) combining text, audio, video, social media posts, and other modalities is non-trivial, (3) long context of media spanning multiple hours, days or even months, (4) user sentiment and media hype-driven stock/crypto price movement and volatility, (5) difficulties with traditional statistical methods (6) misinformation and non-interpretability of financial systems leading to massive losses and bankruptcies.
        </p>

        <p>
          At the AAAI-2023 Workshop on Multimodal AI for Financial Forecasting (Muffin@AAAI2023), we aim to bring together researchers from natural language processing, computer vision, speech recognition, machine learning, statistics, and quantitative trading communities to expand research on the intersection of AI and financial time series forecasting. We will also organize 2 shared tasks in this workshop – (1) Stock Price and Volatility Prediction post-Monetary Conference Calls and (2) Cryptocurrency Bubble Detection.
        </p>

        <p>Please refer to <a href="shared_task.html">shared tasks</a> page for more information.</p>
      </div>
    </section>
  </main>
</div>

<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: lightgray;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Topics</h6>
        <p>
          This workshop will hold a research track and a shared task track. The research track aims to explore recent advances and challenges of multimodal AI for finance. As this topic is an inherently multi-modal subject, researchers from artificial intelligence, computer vision, speech processing, natural language processing, data mining, statistics, optimization, and other fields are invited to submit papers on recent advances, resources, tools, and challenges on the broad theme of Multimodal AI for finance. The topics of the workshop include but are not limited to the following:
        </p>

        <ul>
          <li>Transformer models / Self-supervised / Transfer Learning on Financial Data</li>
          <li>Machine Learning for Finance</li>
          <li>Natural Language Processing and Speech Applications for Finance</li>
          <li>Conversational dialogue modeling for Financial Conference Calls</li>
          <li>Social media and User NLP for Finance</li>
          <li>Entity extraction and linking, Named-entity recognition, information extraction, relationship extraction, ontology learning in financial documents</li>
          <li>Financial Document Processing </li>
          <li>Multi-modal financial knowledge discovery</li>
          <li>Financial Event detection from Multimedia</li>
          <li>Visual-linguistic learning for financial video analysis</li>
          <li>Video understanding (human behavior cognition, topic mining, facial expression detection, emotion detection, deception detection, gait and posture analysis, etc.)</li>
          <li>Data annotation, acquisition, augmentation, feature engineering, for financial/time-series analysis</li>
          <li>Bias analysis and mitigation in financial models and data</li>
          <li>Statistical Modeling for Time Series Forecasting</li>
          <li>Interpretability and explainability for financial AI models</li>
          <li>Privacy-preserving AI for finance</li>
        </ul>
      </div>
    </section>
  </main>
</div>

<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Important Dates</h6>
        <ul>
          <li>Paper submission deadline: December 23, 2022</li>
          <li>Acceptance notification: January 5, 2023</li>
          <li>Camera-ready submission: January 15, 2023</li>
          <li><strong>Muffin workshop at AAAI 2023:</strong> Feb 14, 2023: 8:30 AM-12:30 PM</li>
        </ul>
        <p>All deadlines are “anywhere on earth” (UTC-12)</p>
      </div>
    </section>
  </main>
</div>
<!-- ################################################################################################ -->
<div class="wrapper row3" style="background-color: lightgray;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">Submission</h6>
        <p>Authors are invited to submit their unpublished work that represents novel research.
           The papers should be written in English using the AAAI-23 author kit
           and follow the AAAI 2023 formatting guidelines.
           Authors can also submit the supplementary materials, including technical appendices,
           source codes, datasets, and multimedia appendices.
           All submissions, including the main paper and its supplementary materials, should be fully anonymized.
           For more information on formatting and anonymity guidelines, please refer to AAAI 2023 call for paper page.
        </p>

        <p>All papers will be double blind peer reviewed. Muffin workshop accepts both long papers and short papers:</p>
        <ul>
          <li>
            <p>
              Short Paper: Up to 4 pages of content including the references.
              Upon the acceptance, the authors are provided with 1 more page to address the reviewer's comments.
            </p>
          </li>
          <li>
            <p>
              Long Paper: Up to 8 pages of content including the references.
              Upon the acceptance, the authors are provided with 1 more page to address the reviewer's comments.
            </p>
          </li>
          <li>
            <p>
              Shared Task Track:  Participants are invited to take part in <a href="https://muffin-aaai23.github.io/shared_task.html">shared tasks</a>: (1) Financial Prediction from Conference Call Videos and (2) Cryptocurrency Bubble Detection. Participants are invited to submit a system paper of 4-8 pages of content including the references.
             </p>
          </li>
        </ul>

        <p>Two reviewers with the same technical expertise will review each paper.
           Authors of the accepted papers will present their work in either the Oral or Poster session.
           All accepted papers will appear on the workshop proceedings that will be published on <a
                    href="http://ceur-ws.org/">CEUR-WS</a>.
           The authors will keep the copyright of their papers that are published on <a
                    href="http://ceur-ws.org/">CEUR-WS</a>.
           The workshop proceedings will be indexed by <a href="https://dblp.org/">DBLP</a>.
        </p>
        <p>Paper must be submitted using <a href="https://easychair.org/conferences/?conf=muffinaaai2023">EasyChair</a>.
           For information on System Paper submission for the share tasks, please refer to our <a
                    href="shared_task.html">shared tasks</a> page.</p>
        <p></p>

          </p>
      </div>
    </section>
  </main>
</div>


<div class="wrapper row3" style="background-color: midnightblue;">
  <main class="hoc container clear">
    <div class="clear">
      <p style="color: antiquewhite;">Contact us: muffin-aaai23@googlegroups.com</p>
    </div>
  </main>
</div>



<a id="backtotop" href="#top"><i class="fa fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="layout/scripts/jquery.min.js"></script>
<script src="layout/scripts/jquery.backtotop.js"></script>
<script src="layout/scripts/jquery.mobilemenu.js"></script>
</body>
</html>
